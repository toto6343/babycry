"""
API Blueprint - í•µì‹¬ ìš¸ìŒ ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸ ë° FastAPI ë¼ìš°íŠ¸ í˜¸í™˜ ëª¨ë“ˆ
app.pyì˜ ë©”ì¸ ê¸°ëŠ¥ì„ ë³´ì™„í•˜ëŠ” ë ˆê±°ì‹œ í˜¸í™˜ ë¼ìš°íŠ¸ì™€ ìµœì‹  FastAPI ë¼ìš°íŠ¸ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
"""
from flask import Blueprint, request, jsonify
from flask_jwt_extended import jwt_required
from backend.models.classifier import CryClassifier
from pathlib import Path
import os
from datetime import datetime
import json
import librosa
import time
import traceback
import requests
from requests.exceptions import ReadTimeout
from backend.services.chatbot_service import ChatbotService

# FastAPI Imports
from fastapi import APIRouter
from fastapi import Query, File, UploadFile, Form, HTTPException, Request
from fastapi.responses import JSONResponse
from dotenv import load_dotenv
load_dotenv()

NOTIFICATION_URL = os.getenv(
    "NOTIFICATION_URL",
    "http://localhost:4000/api/analysis/result"
)

try:
    from backend.services.music_service import get_music_service
    MUSIC_SERVICE_AVAILABLE = True
except ImportError:
    MUSIC_SERVICE_AVAILABLE = False
    print("âš ï¸ LocalMusicService not available. Music playback will be skipped.")

# StorageManager import
try:
    # ê°€ì •: backend.utils.storage_managerê°€ ì¡´ì¬í•˜ë©° get_storage_manager í•¨ìˆ˜ë¥¼ ì œê³µ
    from backend.utils.storage_manager import get_storage_manager
    STORAGE_MANAGER_AVAILABLE = True
except ImportError:
    STORAGE_MANAGER_AVAILABLE = False
    print("âš ï¸ StorageManager not available in Blueprint. Falling back to JSON history.")

def notify_node_backend(event_data):
    """
    Node ì•Œë¦¼ ì„œë²„ë¡œ ë¶„ì„ ê²°ê³¼ ì „ë‹¬
    """
    try:
        if not event_data.get("event_id"):
            print("âš ï¸ event_id ì—†ìŒ, Node ì•Œë¦¼ ìƒëµ")
            return

        payload = {
            "cryEventId": event_data["event_id"],
            "infantId": event_data.get("infant_id", 1),
            "isCrying": event_data.get("isCrying", False),
            "cause": event_data.get("reason", "unknown"),
            "severity": event_data.get("severity", "Unknown"),
        }

        print(f"ğŸ“¨ Node ì•Œë¦¼ ì„œë²„ í˜¸ì¶œ: {NOTIFICATION_URL} / payload={payload}")
        
        response = requests.post(
            NOTIFICATION_URL,
            json=payload,
            timeout=(3, 10),
        )
        print(f"ğŸ“¨ Node ì‘ë‹µ ì½”ë“œ: {response.status_code}")

    except ReadTimeout:
        # Node ìª½ì—ì„œ ì²˜ë¦¬ ì¤‘ì´ì§€ë§Œ ì‘ë‹µì´ ëŠ¦ëŠ” ê²½ìš°
        print("âš ï¸ Node ì•Œë¦¼ ì„œë²„ ì‘ë‹µ íƒ€ì„ì•„ì›ƒ(í•˜ì§€ë§Œ ìš”ì²­ì€ ì „ì†¡ë¨)")

    except Exception as e:
        print(f"âš ï¸ Node ì•Œë¦¼ ì„œë²„ í˜¸ì¶œ ì‹¤íŒ¨: {e}")


# --- ì „ì—­ ìƒìˆ˜ ë° ì´ˆê¸°í™” ---

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ (íŒŒì¼ ìœ„ì¹˜ì—ì„œ 3ë‹¨ê³„ ìœ„)
PROJECT_ROOT = Path(__file__).resolve().parents[2]
# FastAPI íŒŒì¼ ì €ì¥ì„ ìœ„í•œ ê²½ë¡œ ì •ì˜ (ëˆ„ë½ë˜ì—ˆë˜ ë¶€ë¶„)
UPLOADS_PATH = PROJECT_ROOT / 'uploads'
os.makedirs(UPLOADS_PATH, exist_ok=True) # í´ë” ìƒì„±

# FastAPI APIRouter ì •ì˜
router = APIRouter(prefix="/api", tags=["api"])

# ì „ì—­ classifier ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤)
_classifier_instance = None

chatbot = ChatbotService()

# --- Helper Functions ---

def get_classifier():
    """Classifier ì‹±ê¸€í†¤ - í•œ ë²ˆë§Œ ë¡œë“œ"""
    global _classifier_instance
    
    if _classifier_instance is None:
        model_path = PROJECT_ROOT / 'models' / 'baby_cry_v15_1_detector.pkl'
        sensitivity = os.getenv('CRY_SENSITIVITY', 'balanced')
        
        print(f"ğŸ”§ [Blueprint] Initializing V15.1 Classifier...")
        print(f"   Sensitivity: {sensitivity}")
        
        _classifier_instance = CryClassifier(
            str(PROJECT_ROOT / 'Dataset'),
            sensitivity=sensitivity
        )
        _classifier_instance.load_model(str(model_path))
    
    return _classifier_instance

def get_recommended_actions(reason, severity):
    """ì›ì¸ì— ë”°ë¥¸ ì¡°ì¹˜ ì¶”ì²œ"""
    action_map = {
        'hungry': [
            {'action_type': 'feeding', 'detail': 'ìˆ˜ìœ í•˜ê¸° (ë§ˆì§€ë§‰ ìˆ˜ìœ  í›„ 2-3ì‹œê°„ ê²½ê³¼ í™•ì¸)', 'priority': 1},
            {'action_type': 'check_diaper', 'detail': 'ê¸°ì €ê·€ í™•ì¸', 'priority': 2}
        ],
        'burping': [
            {'action_type': 'burping', 'detail': 'ë“±ì„ ë‘ë“œë ¤ íŠ¸ë¦¼ ì‹œí‚¤ê¸°', 'priority': 1},
            {'action_type': 'position', 'detail': 'ì„¸ì›Œì„œ ì•ˆì•„ì£¼ê¸°', 'priority': 2}
        ],
        # ... (ë‚˜ë¨¸ì§€ action_map í•­ëª©ì€ ìƒëµ ì—†ì´ ìœ ì§€)
        'belly_pain': [
            {'action_type': 'massage', 'detail': 'ë°°ë¥¼ ì‹œê³„ë°©í–¥ìœ¼ë¡œ ë¶€ë“œëŸ½ê²Œ ë§ˆì‚¬ì§€', 'priority': 1},
            {'action_type': 'medical', 'detail': 'ğŸš¨ ì¦ìƒì´ ì‹¬í•˜ë©´ ì¦‰ì‹œ ì†Œì•„ê³¼ ìƒë‹´', 'priority': 2},
            {'action_type': 'warmth', 'detail': 'ë”°ëœ»í•œ ìˆ˜ê±´ ë°°ì— ëŒ€ì£¼ê¸°', 'priority': 3}
        ],
        'tired': [
            {'action_type': 'sleep_environment', 'detail': 'ì¡°ìš©í•˜ê³  ì–´ë‘ìš´ í™˜ê²½ ë§Œë“¤ê¸°', 'priority': 1},
            {'action_type': 'soothing', 'detail': 'ë¶€ë“œëŸ½ê²Œ í”ë“¤ë©° ë‹¬ë˜ê¸°', 'priority': 2},
            {'action_type': 'white_noise', 'detail': 'ë°±ìƒ‰ì†ŒìŒ ë“¤ë ¤ì£¼ê¸°', 'priority': 3}
        ],
        'cold_hot': [
            {'action_type': 'temperature', 'detail': 'ì²´ì˜¨ ë° ì‹¤ë‚´ì˜¨ë„ í™•ì¸ (ì ì •: 20-22Â°C)', 'priority': 1},
            {'action_type': 'clothing', 'detail': 'ì˜· ë‘ê»˜ ì¡°ì ˆí•˜ê¸°', 'priority': 2}
        ],
        'discomfort': [
            {'action_type': 'check_all', 'detail': 'ì „ë°˜ì ì¸ ë¶ˆí¸ ìš”ì†Œ ì ê²€', 'priority': 1},
            {'action_type': 'position', 'detail': 'ìì„¸ ë°”ê¿”ì£¼ê¸°', 'priority': 2},
            {'action_type': 'comfort', 'detail': 'ì•ˆì•„ì„œ ë‹¬ë˜ì£¼ê¸°', 'priority': 3}
        ],
        'emotional': [
            {'action_type': 'comfort', 'detail': 'ì•ˆì •ê°ê³¼ ì• ì • í‘œí˜„í•˜ê¸°', 'priority': 1},
            {'action_type': 'attention', 'detail': 'ëˆˆ ë§ì¶”ê³  ë§ ê±¸ì–´ì£¼ê¸°', 'priority': 2},
            {'action_type': 'play', 'detail': 'ê°€ë²¼ìš´ ë†€ì´ë‚˜ ë…¸ë˜', 'priority': 3}
        ]
    }
    
    actions = action_map.get(reason, [
        {'action_type': 'check_all', 'detail': 'ì „ë°˜ì ì¸ ìƒíƒœ í™•ì¸', 'priority': 1}
    ])
    
    if severity == 'high':
        actions.insert(0, {
            'action_type': 'urgent',
            'detail': 'âš ï¸ ì¦‰ì‹œ ì•„ê¸° ìƒíƒœ í™•ì¸ í•„ìš”',
            'priority': 0
        })
    
    return actions

# ====================================================================
# ## FastAPI APIRouter ë¼ìš°íŠ¸
# ====================================================================

@router.get("/health")
async def health():
    return {"status": "ok", "backend": "python", "model_loaded": _classifier_instance is not None}

@router.post("/upload")
async def upload_audio(
    audio: UploadFile = File(...), 
    infant_id: int = Form(0), 
    guardian_id: int = Form(0), # ì¶”ê°€ëœ í•„ë“œ
    sensitivity: str = Form("balanced")
):
    """
    FastAPI ê¸°ë°˜ ì˜¤ë””ì˜¤ ì—…ë¡œë“œ ë° ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸
    """
    dest = None
    try:
        if not audio or not audio.filename:
            raise HTTPException(status_code=400, detail="no_file")

        # íŒŒì¼ ì €ì¥ (UPLOADS_PATH ì‚¬ìš©)
        timestamp = int(time.time()*1000)
        dest = UPLOADS_PATH / f"{timestamp}_{Path(audio.filename).name}"
        
        with dest.open("wb") as f:
            f.write(await audio.read())
        
        # ëª¨ë¸ ì˜ˆì¸¡ (Flask ë¡œì§ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•œë‹¤ê³  ê°€ì •í•˜ê³  í•¨ìˆ˜ë¡œ ë¶„ë¦¬ í•„ìš”)
        classifier = get_classifier()
        classifier.set_sensitivity(sensitivity)

        result = classifier.predict_with_confidence(str(dest))
        
        now = datetime.now()
        korean_days = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"]

        prediction = result['prediction']
        confidence = result['confidence']
        severity = result['severity']
        
        # ë©”íƒ€ì •ë³´ ì¶”ì¶œ (ì„ì‹œ)
        try:
            audio_data, sample_rate = librosa.load(str(dest), sr=None)
            duration_ms = int(len(audio_data) / sample_rate * 1000)
        except Exception:
            duration_ms = 3000
            sample_rate = 16000

        response_data = {
            "timestamp": now.isoformat(),
            "reason": prediction,
            "duration": duration_ms // 1000,
            "severity": severity,
            "infant_id": infant_id,
            "guardian_id": guardian_id,
            "confidence": confidence,
            "success": True,
            "isCrying": prediction != 'not_cry',
            "recommended_actions": get_recommended_actions(prediction, severity) if prediction != 'not_cry' else [],
            "audio_file": Path(dest).name,
            "storage_uri": str(dest.relative_to(PROJECT_ROOT)),
            "model_version": "v15.1"
        }

        # StorageManagerë¡œ ì €ì¥ (ë¡œì§ ë‹¨ìˆœí™”)
        if STORAGE_MANAGER_AVAILABLE:
            storage = get_storage_manager()
            response_data = storage.save_complete_event(response_data)
        
        try:
            if MUSIC_SERVICE_AVAILABLE:
                cry_cause = prediction  # reason ê°’ (hungry / tired / emotional ...)
                if cry_cause in ("emotional", "tired"):
                    music_service = get_music_service()
                    music_info = music_service.play_for_cause(cry_cause)
                    print(f"ğŸµ Music playback result: {music_info}")
        except Exception as e:
            print(f"âš ï¸ Music playback failed: {e}")

        try:
            notify_node_backend(response_data)
        except Exception as e:
            print(f"âš ï¸ notify_node_backend ì‹¤íŒ¨: {e}")
        
        return JSONResponse(content=response_data)
        
    except HTTPException:
        raise
    except Exception as e:
        tb = traceback.format_exc()
        print("Upload handler error:", e)
        print(tb)
        return JSONResponse(status_code=503, content={
            "success": False,
            "error": str(e),
            "trace": tb.splitlines()[-10:]
        })
    finally:
        # NOTE: Flaskì™€ ë™ì¼í•˜ê²Œ íŒŒì¼ ì‚­ì œëŠ” ì •ì±…ì— ë”°ë¼ ì£¼ì„ ì²˜ë¦¬
        # if dest and dest.exists():
        #     os.remove(dest)
        pass

@router.get("/dashboard")
async def get_dashboard(infant_id: int = Query(..., description="ID of the infant")):
    """
    ì•„ê¸° IDë³„ ëŒ€ì‹œë³´ë“œ ë°ì´í„° ë°˜í™˜
    """
    try:
        # TODO: replace with actual data retrieval (db/service)
        if not STORAGE_MANAGER_AVAILABLE:
            raise HTTPException(status_code=503, detail="StorageManager not available for dashboard.")

        storage = get_storage_manager()
        summary = storage.get_insights_summary(infant_id, days=7) # ì˜ˆì‹œë¡œ 7ì¼ì¹˜ ìš”ì•½

        data = {
            "success": True,
            "infant_id": infant_id,
            "recent_events": storage.get_cry_events(infant_id, limit=5),
            "summary": summary,
            "next_cry_prediction": None,
            "patterns": None,
        }
        return JSONResponse(content=data)
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Dashboard error: {str(e)}")

@router.post("/chatbot")
async def chatbot_endpoint(request: Request):
    data = await request.json()
    
    infant_id = data.get("infant_id")
    guardian_id = data.get("guardian_id", 1)
    user_message = data.get("message")
    history = data.get("history", [])
    
    if not user_message:
        return {"error": "message is required"}

    try:
        response = chatbot.generate_response(
            infant_id=infant_id,
            guardian_id=guardian_id,
            user_message=user_message,
            conversation_history=history
        )
        return response
    except Exception as e:
        return {"error": str(e)}

# --- End of File ---