"""
CryClassifier - Baby Cry Classification Model Wrapper
V15.1 í˜¸í™˜ ë²„ì „ (improved_v18.py ê¸°ë°˜)

ì´ íŒŒì¼ì€ backend/models/classifier.pyì— ì €ì¥í•˜ì„¸ìš”.
"""

import os
import numpy as np
import librosa
from pathlib import Path
import joblib
import warnings
warnings.filterwarnings('ignore')


class CryClassifier:
    """
    ì•„ê¸° ìš¸ìŒì†Œë¦¬ ë¶„ë¥˜ ëª¨ë¸ ë˜í¼
    improved_v18.pyì˜ V15_1AdaptivePredictorë¥¼ APIì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë˜í•‘
    """
    
    def __init__(self, dataset_path, sensitivity='balanced'):
        """
        Parameters:
        -----------
        dataset_path : str
            ë°ì´í„°ì…‹ ê²½ë¡œ (í•™ìŠµ ì‹œ í•„ìš”, ì˜ˆì¸¡ë§Œ í•  ê²½ìš° ë¹ˆ ë¬¸ìì—´ ê°€ëŠ¥)
        sensitivity : str
            'high', 'balanced', 'precise' ì¤‘ ì„ íƒ
        """
        self.dataset_path = Path(dataset_path) if dataset_path else None
        
        if sensitivity not in ['high', 'balanced', 'precise']:
            print(f"âš ï¸  Invalid sensitivity '{sensitivity}', using 'balanced'")
            sensitivity = 'balanced'
        
        self.sensitivity = sensitivity
        
        # ëª¨ë¸ ì»´í¬ë„ŒíŠ¸ (load_modelì—ì„œ ì´ˆê¸°í™”ë¨)
        self.detector = None
        self.stage1 = None
        self.cascade_filter = None
        self.stage2_nonpain = None
        
        self.scaler_phase1 = None
        self.scaler_stage1 = None
        self.scaler_cascade = None
        self.scaler_stage2 = None
        
        self.thresholds = None
        
        # ì¹´í…Œê³ ë¦¬ ë§¤í•‘
        self.category_mapping = {
            'belly_pain': 'belly_pain',
            'cold_hot': 'cold_hot',
            'burping': 'burping',
            'discomfort': 'discomfort',
            'hungry': 'hungry',
            'tired': 'tired',
            'emotional': 'emotional'
        }
    
    def set_sensitivity(self, sensitivity):
        """ë¯¼ê°ë„ ëª¨ë“œ ë³€ê²½"""
        if sensitivity not in ['high', 'balanced', 'precise']:
            print(f"âš ï¸  Invalid sensitivity '{sensitivity}', keeping current")
            return
        
        old_sensitivity = self.sensitivity
        self.sensitivity = sensitivity
        print(f"âœ… Sensitivity changed: {old_sensitivity} â†’ {sensitivity}")
        
        if self.thresholds and 'cascade_thresholds' in self.thresholds:
            cascade_threshold = self.thresholds['cascade_thresholds'].get(sensitivity, 0.365)
            print(f"   Cascade threshold: {cascade_threshold:.3f}")
    
    def load_model(self, model_prefix: str):
        """
        ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ
        
        Parameters:
        -----------
        model_prefix : str
            ëª¨ë¸ íŒŒì¼ì˜ prefix (ì˜ˆ: C:\\path\\to\\models\\baby_cry_v15_1)
            ë˜ëŠ” ì „ì²´ ê²½ë¡œ (ì˜ˆ: C:\\path\\to\\models\\baby_cry_v15_1_detector.pkl)
            
            â­ ìˆ˜ì •: ì „ì²´ íŒŒì¼ëª…ì´ ì „ë‹¬ë˜ì–´ë„ ìë™ìœ¼ë¡œ prefix ì¶”ì¶œ
        """
        try:
            # â­ í•µì‹¬ ìˆ˜ì •: _detector.pkl, _stage1_pain.pkl ë“±ì˜ suffix ì œê±°
            model_prefix = str(model_prefix)
            suffixes_to_remove = [
                '_detector.pkl',
                '_stage1_pain.pkl', 
                '_stage1_ensemble.pkl',
                '_scaler_phase1.pkl',
                '_scaler_stage1.pkl',
                '_cascade.pkl',
                '_scaler_cascade.pkl',
                '_nonpain.pkl',
                '_scaler_stage2.pkl',
                '_thresholds.pkl'
            ]
            
            for suffix in suffixes_to_remove:
                if model_prefix.endswith(suffix):
                    model_prefix = model_prefix[:-len(suffix)]
                    print(f"ğŸ”§ Removed suffix '{suffix}' from path")
                    break
            
            print(f"ğŸ” Loading models with prefix: {model_prefix}")
            
            # Phase 1: Cry Detection (í•„ìˆ˜)
            self.detector = joblib.load(f"{model_prefix}_detector.pkl")
            self.scaler_phase1 = joblib.load(f"{model_prefix}_scaler_phase1.pkl")
            print("âœ“ Loaded Phase 1: Cry Detection")
            
            # Stage 1: Pain Detection
            # â­ í•µì‹¬ ìˆ˜ì •: improved_v18.pyëŠ” _stage1_pain.pklë¡œ ì €ì¥í•¨
            stage1_loaded = False
            stage1_files_to_try = [
                f"{model_prefix}_stage1_pain.pkl",      # âœ… improved_v18.pyê°€ ì €ì¥í•˜ëŠ” ì´ë¦„
                f"{model_prefix}_stage1_ensemble.pkl",  # ê¸°ì¡´ ì´ë¦„ (í˜¸í™˜ì„±)
            ]
            
            for stage1_file in stage1_files_to_try:
                try:
                    self.stage1 = joblib.load(stage1_file)
                    print(f"âœ“ Loaded Stage 1: {Path(stage1_file).name}")
                    stage1_loaded = True
                    break
                except FileNotFoundError:
                    continue
            
            if not stage1_loaded:
                raise FileNotFoundError("Stage 1 pain detector model not found")
            
            # Scaler for Stage 1
            try:
                self.scaler_stage1 = joblib.load(f"{model_prefix}_scaler_stage1.pkl")
                print("âœ“ Loaded scaler_stage1")
            except FileNotFoundError:
                print("âš  Warning: scaler_stage1 not found, using scaler_phase1")
                self.scaler_stage1 = self.scaler_phase1
            
            # Stage 1.5: Cascade Filter (ì„ íƒì‚¬í•­)
            try:
                self.cascade_filter = joblib.load(f"{model_prefix}_cascade.pkl")
                print("âœ“ Loaded Cascade Filter")
            except FileNotFoundError:
                print("âš  Warning: Cascade filter not found")
                self.cascade_filter = None
            
            # Scaler for Cascade
            try:
                self.scaler_cascade = joblib.load(f"{model_prefix}_scaler_cascade.pkl")
                print("âœ“ Loaded scaler_cascade")
            except FileNotFoundError:
                print("âš  Warning: scaler_cascade not found, using scaler_stage1")
                self.scaler_cascade = self.scaler_stage1 if self.scaler_stage1 else self.scaler_phase1
            
            # Stage 2: Non-pain classification (ì„ íƒì‚¬í•­)
            try:
                self.stage2_nonpain = joblib.load(f"{model_prefix}_nonpain.pkl")
                self.scaler_stage2 = joblib.load(f"{model_prefix}_scaler_stage2.pkl")
                print("âœ“ Loaded Stage 2: Non-pain classifier")
            except FileNotFoundError:
                print("âš  Warning: Stage 2 models not found")
                self.stage2_nonpain = None
                self.scaler_stage2 = None
            
            # Thresholds
            try:
                self.thresholds = joblib.load(f"{model_prefix}_thresholds.pkl")
                print("âœ“ Loaded thresholds")
                
                if 'cascade_thresholds' in self.thresholds:
                    cascade_threshold = self.thresholds['cascade_thresholds'].get(self.sensitivity, 0.365)
                    print(f"   Current sensitivity: {self.sensitivity} (threshold={cascade_threshold:.3f})")
            except FileNotFoundError:
                print("âš  Warning: Using default thresholds")
                self.thresholds = {
                    'pain_threshold_primary': 0.5,
                    'cascade_thresholds': {
                        'high': 0.25,
                        'balanced': 0.365,
                        'precise': 0.50
                    },
                    'confidence_threshold_low': 0.4,
                    'confidence_threshold_high': 0.7
                }
            
            print(f"âœ… All models loaded successfully!")
            
        except FileNotFoundError as e:
            raise RuntimeError(f"Model load failed - File not found: {e}")
        except Exception as e:
            raise RuntimeError(f"Model load failed: {e}")
    
    def extract_features(self, audio_path, duration=3.0):
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì—ì„œ íŠ¹ì§• ì¶”ì¶œ
        improved_v18.pyì˜ extract_featuresë¥¼ ê°„ì†Œí™”í•œ ë²„ì „
        """
        try:
            y, sr = librosa.load(audio_path, duration=duration, sr=22050)
            
            if len(y) == 0:
                return None
            
            features = []
            
            # MFCC (78 features)
            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
            features.extend([
                np.mean(mfcc, axis=1),
                np.std(mfcc, axis=1),
                np.max(mfcc, axis=1),
                np.min(mfcc, axis=1)
            ])
            
            mfcc_delta = librosa.feature.delta(mfcc)
            features.append(np.mean(mfcc_delta, axis=1))
            
            mfcc_delta2 = librosa.feature.delta(mfcc, order=2)
            features.append(np.mean(mfcc_delta2, axis=1))
            
            # Spectral (12 features)
            spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
            spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]
            spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]
            spectral_flatness = librosa.feature.spectral_flatness(y=y)[0]
            
            features.extend([
                [np.mean(spectral_centroids), np.std(spectral_centroids)],
                [np.mean(spectral_rolloff), np.std(spectral_rolloff)],
                [np.mean(spectral_bandwidth), np.std(spectral_bandwidth)],
                [np.mean(spectral_flatness), np.std(spectral_flatness), 
                 np.max(spectral_flatness), np.min(spectral_flatness)]
            ])
            
            # Energy (7 features)
            zcr = librosa.feature.zero_crossing_rate(y)[0]
            rms = librosa.feature.rms(y=y)[0]
            features.extend([
                [np.mean(zcr), np.std(zcr)],
                [np.mean(rms), np.std(rms), np.max(rms)]
            ])
            
            # Harmonic (8 features)
            chroma = librosa.feature.chroma_stft(y=y, sr=sr)
            mel = librosa.feature.melspectrogram(y=y, sr=sr)
            contrast = librosa.feature.spectral_contrast(y=y, sr=sr)
            tonnetz = librosa.feature.tonnetz(y=y, sr=sr)
            
            features.extend([
                [np.mean(chroma), np.std(chroma)],
                [np.mean(mel), np.std(mel)],
                [np.mean(contrast), np.std(contrast)],
                [np.mean(tonnetz), np.std(tonnetz)]
            ])
            
            # Temporal (4 features)
            tempo, _ = librosa.beat.beat_track(y=y, sr=sr, start_bpm=120)
            onset_env = librosa.onset.onset_strength(y=y, sr=sr)
            features.extend([
                [tempo],
                [np.mean(onset_env), np.std(onset_env), np.max(onset_env)]
            ])
            
            feature_vector = np.concatenate([np.array(f).flatten() for f in features])
            feature_vector = np.nan_to_num(feature_vector, nan=0.0, posinf=0.0, neginf=0.0)
            
            return feature_vector
            
        except Exception as e:
            print(f"âš ï¸  Feature extraction error: {e}")
            return None
    
    def predict_with_confidence(self, audio_path):
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„ì„ ë° ì˜ˆì¸¡
        
        Returns:
        --------
        dict : {
            'prediction': str,  # ì˜ˆì¸¡ ê²°ê³¼
            'confidence': float,  # ì‹ ë¢°ë„
            'severity': str,  # ì‹¬ê°ë„ (High/Medium/Low)
            'probabilities': dict,  # ê° ë‹¨ê³„ë³„ í™•ë¥ 
            'stage': str  # ì–´ëŠ ë‹¨ê³„ì—ì„œ ê²°ì •ë˜ì—ˆëŠ”ì§€
        }
        """
        if not self.detector:
            return {
                'prediction': 'error',
                'confidence': 0.0,
                'severity': 'Unknown',
                'error': 'Model not loaded'
            }
        
        # íŠ¹ì§• ì¶”ì¶œ
        features = self.extract_features(audio_path)
        
        if features is None:
            return {
                'prediction': 'error',
                'confidence': 0.0,
                'severity': 'Unknown',
                'error': 'Feature extraction failed'
            }
        
        features = features.reshape(1, -1)
        
        # Phase 1: Cry Detection
        features_scaled_phase1 = self.scaler_phase1.transform(features)
        cry_proba = self.detector.predict_proba(features_scaled_phase1)[0]
        is_cry = self.detector.predict(features_scaled_phase1)[0]
        
        # â­ ë°©ì–´ ì½”ë“œ: cry_probaê°€ ì˜ˆìƒê³¼ ë‹¤ë¥¸ í˜•íƒœì¼ ê²½ìš° ì²˜ë¦¬
        if len(cry_proba) == 1:
            # ë‹¨ì¼ í´ë˜ìŠ¤ë§Œ ì˜ˆì¸¡ëœ ê²½ìš°
            cry_confidence = float(cry_proba[0])
            not_cry_confidence = 1.0 - cry_confidence
            probabilities_dict = {
                'cry': cry_confidence if is_cry == 'cry' else not_cry_confidence,
                'not_cry': not_cry_confidence if is_cry == 'cry' else cry_confidence
            }
        else:
            # ì •ìƒì ì¸ ê²½ìš° (2ê°œ í´ë˜ìŠ¤)
            # detectorì˜ classes_ë¥¼ í™•ì¸í•˜ì—¬ ì˜¬ë°”ë¥¸ ì¸ë±ìŠ¤ ì‚¬ìš©
            classes = self.detector.classes_
            cry_idx = np.where(classes == 'cry')[0]
            not_cry_idx = np.where(classes == 'not_cry')[0]
            
            cry_confidence = float(cry_proba[cry_idx[0]]) if len(cry_idx) > 0 else float(cry_proba[1])
            not_cry_confidence = float(cry_proba[not_cry_idx[0]]) if len(not_cry_idx) > 0 else float(cry_proba[0])
            
            probabilities_dict = {
                'cry': cry_confidence,
                'not_cry': not_cry_confidence
            }
        
        if is_cry == 'not_cry':
            return {
                'prediction': 'not_cry',
                'confidence': not_cry_confidence,
                'severity': 'None',
                'probabilities': probabilities_dict,
                'stage': 'phase1'
            }
        
        # Stage 1: Primary Pain Detection
        features_scaled_stage1 = self.scaler_stage1.transform(features)
        pain_proba_stage1_raw = self.stage1.predict_proba(features_scaled_stage1)[0]
        
        # â­ ë°©ì–´ ì½”ë“œ: pain_proba ì²˜ë¦¬
        if len(pain_proba_stage1_raw) == 1:
            pain_proba_stage1 = float(pain_proba_stage1_raw[0])
        else:
            # Pain í´ë˜ìŠ¤ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
            try:
                pain_idx = list(self.stage1.classes_).index('belly_pain')
                pain_proba_stage1 = float(pain_proba_stage1_raw[pain_idx])
            except (ValueError, AttributeError):
                # ê¸°ë³¸ê°’: ë§ˆì§€ë§‰ ì¸ë±ìŠ¤ ì‚¬ìš©
                pain_proba_stage1 = float(pain_proba_stage1_raw[-1])
        
        pain_threshold_primary = self.thresholds.get('pain_threshold_primary', 0.5)
        is_pain_stage1 = pain_proba_stage1 >= pain_threshold_primary
        
        probabilities = {
            'cry': cry_confidence,
            'pain_stage1': pain_proba_stage1
        }
        
        if not is_pain_stage1:
            # Non-Pain Classification
            if self.stage2_nonpain:
                features_scaled_stage2 = self.scaler_stage2.transform(features)
                category = self.stage2_nonpain.predict(features_scaled_stage2)[0]
                category_proba = self.stage2_nonpain.predict_proba(features_scaled_stage2)[0]
                confidence = float(np.max(category_proba))
                
                return {
                    'prediction': category,
                    'confidence': confidence,
                    'severity': self._get_severity(confidence),
                    'probabilities': probabilities,
                    'stage': 'stage2_nonpain'
                }
            else:
                return {
                    'prediction': 'needs_attention',
                    'confidence': float(1.0 - pain_proba_stage1),
                    'severity': 'Medium',
                    'probabilities': probabilities,
                    'stage': 'stage1_nonpain'
                }
        
        # Stage 1.5: Cascade Filter
        if self.cascade_filter:
            features_scaled_cascade = self.scaler_cascade.transform(features)
            pain_proba_cascade = self.cascade_filter.predict_proba(features_scaled_cascade)[0, 1]
            
            cascade_thresholds = self.thresholds.get('cascade_thresholds', {
                'high': 0.25, 'balanced': 0.365, 'precise': 0.50
            })
            cascade_threshold = cascade_thresholds.get(self.sensitivity, 0.365)
            is_pain_cascade = pain_proba_cascade >= cascade_threshold
            
            probabilities['pain_cascade'] = float(pain_proba_cascade)
            probabilities['cascade_threshold'] = float(cascade_threshold)
            
            if not is_pain_cascade:
                # Filtered by Cascade -> Re-classify as Non-Pain
                if self.stage2_nonpain:
                    features_scaled_stage2 = self.scaler_stage2.transform(features)
                    category = self.stage2_nonpain.predict(features_scaled_stage2)[0]
                    category_proba = self.stage2_nonpain.predict_proba(features_scaled_stage2)[0]
                    confidence = float(np.max(category_proba))
                    
                    return {
                        'prediction': category,
                        'confidence': confidence,
                        'severity': self._get_severity(confidence),
                        'probabilities': probabilities,
                        'stage': 'cascade_filtered'
                    }
                else:
                    return {
                        'prediction': 'needs_attention',
                        'confidence': float(1.0 - pain_proba_cascade),
                        'severity': 'Medium',
                        'probabilities': probabilities,
                        'stage': 'cascade_filtered'
                    }
            
            # Cascade Confirmed -> Pain
            return {
                'prediction': 'belly_pain',
                'confidence': float(pain_proba_cascade),
                'severity': self._get_severity(pain_proba_cascade),
                'probabilities': probabilities,
                'stage': 'cascade_confirmed'
            }
        
        else:
            # No Cascade -> Use Stage 1 only
            return {
                'prediction': 'belly_pain',
                'confidence': float(pain_proba_stage1),
                'severity': self._get_severity(pain_proba_stage1),
                'probabilities': probabilities,
                'stage': 'stage1_pain'
            }
    
    def _get_severity(self, confidence):
        """ì‹ ë¢°ë„ ê¸°ë°˜ ì‹¬ê°ë„ ê³„ì‚°"""
        confidence_threshold_high = self.thresholds.get('confidence_threshold_high', 0.7)
        confidence_threshold_low = self.thresholds.get('confidence_threshold_low', 0.4)
        
        if confidence >= confidence_threshold_high:
            return 'High'
        elif confidence >= confidence_threshold_low:
            return 'Medium'
        else:
            return 'Low'


# â­ ìˆ˜ì •: í…ŒìŠ¤íŠ¸ ì½”ë“œëŠ” ì§ì ‘ ì‹¤í–‰í•  ë•Œë§Œ ë™ì‘í•˜ë„ë¡
if __name__ == "__main__":
    print("CryClassifier Test")
    print("=" * 60)
    
    # ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
    try:
        classifier = CryClassifier('', sensitivity='balanced')
        classifier.load_model('./models/baby_cry_v15_1')
        print("\nâœ… Model load test: SUCCESS")
    except Exception as e:
        print(f"\nâŒ Model load test: FAILED - {e}")